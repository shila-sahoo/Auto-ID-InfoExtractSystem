{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05bed7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from paddleocr import PaddleOCR\n",
    "#from retinaface import RetinaFace\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "import datetime\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "# import os.path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ed00a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/nemo/data\n",
      "/workspace/nemo/data/aadhaar_detection/aadhaar_detection_vid/aadhar_detection_v3/model_result5/YV8/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "# project_root_path=os.path.abspath(os.path.join(os.path.dirname('__file__'), \"..\"))\n",
    "file_path0 = os.path.abspath(os.path.join(os.path.dirname('__file__'), \"..\"))\n",
    "print(file_path0)\n",
    "# model_path = os.path.join(file_path0, 'aadhar_information_fetch','model_weight','best.pt')\n",
    "model_path = \"/workspace/nemo/data/aadhaar_detection/aadhaar_detection_vid/aadhar_detection_v3/model_result5/YV8/weights/best.pt\"\n",
    "print(model_path)\n",
    "labels = {\n",
    "    'aadhaar': 0.0\n",
    "}\n",
    "image_path=\"/workspace/nemo/data/aadhar_information_fetch/aadhar_prediction.jpg\"\n",
    "cv2.imread\n",
    "model = YOLO(model_path)\n",
    "# results = model(conf=0.30, source=image_path)[0]  # results list\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6653c707",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-5): 6 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-5): 6 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (11): Concat()\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (14): Concat()\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat()\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat()\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(320, 7, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(320, 7, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1132dd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /workspace/nemo/data/aadhar_information_fetch/aadhar_prediction.jpg: 256x256 1 aadhar, 4 names, 3 dobs, 4 genders, 1 aadhar_number, 5.4ms\n",
      "Speed: 0.7ms preprocess, 5.4ms inference, 1.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'aadhar', 1: 'name', 2: 'dob', 3: 'gender', 4: 'aadhar_number', 5: 'v_id', 6: 'aadhar_back'}\n",
      "obb: None\n",
      "orig_img: array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)\n",
      "orig_shape: (532, 532)\n",
      "path: '/workspace/nemo/data/aadhar_information_fetch/aadhar_prediction.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/detect/predict3'\n",
      "speed: {'preprocess': 0.6964206695556641, 'inference': 5.436897277832031, 'postprocess': 1.3401508331298828}]\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# torch.cuda.empty_cache()\n",
    "results = model(image_path,save=True)  # results list\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768dc234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb595b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class aadhar_check:\n",
    "    def __init__(self, image_path:str):\n",
    "        self.image_path = image_path\n",
    "       \n",
    "    def model_prediction(self):\n",
    "        detected = \"Not_detected\"\n",
    "        info_table = { \"image_quality\":None, \"image_dimension\":None, \"name\":None, \"dob\":None, \"number\":None, \"vid\":None};\n",
    "        model = YOLO(model_path)\n",
    "        results = model(conf=0.30, source=self.image_path)[0]  # results list\n",
    "        print(results)\n",
    "        print(results[0].boxes.data)\n",
    "        result=results[0].boxes.data\n",
    "        result1=result\n",
    "        confidence_score=results[0].boxes.conf.tolist()\n",
    "        all_class=results[0].boxes.cls.tolist()\n",
    "        z=results[0].boxes.cls\n",
    "        if  (labels[\"aadhaar\"] in z ):\n",
    "            detected=\"Aadhaar Card\"\n",
    "        img = cv2.imread(self.image_path)\n",
    "        for r in results.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = r\n",
    "            if class_id == 0.0:   \n",
    "                image_crop = img[int(y1):int(y2), int(x1):int(x2), :]\n",
    "                cv2.imwrite('adhar_test.jpg', image_crop)\n",
    "#                 break\n",
    "#         try:\n",
    "            resp = RetinaFace.detect_faces(image_crop)\n",
    "            \n",
    "#         except:\n",
    "#             image_quality = \"bad\"\n",
    "        \n",
    "def main():\n",
    "    image_path=\"/workspace/nemo/data/aadhaar_detection/aadhar_image_quality/images/192535220000051_aadhaar.jpg\"\n",
    "    doc_id = aadhar_check(image_path)\n",
    "    doc_id.model_prediction()\n",
    "#     print(id_info)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0bd25025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def pad_to_square(image_path, output_path):\n",
    "    # Read the input image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Get the dimensions of the input image\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    # Determine the size of the target square image (use the maximum dimension)\n",
    "    target_size = max(height, width)\n",
    "\n",
    "    # Calculate the padding needed on each side\n",
    "    top_pad = (target_size - height) // 2\n",
    "    bottom_pad = target_size - height - top_pad\n",
    "    left_pad = (target_size - width) // 2\n",
    "    right_pad = target_size - width - left_pad\n",
    "\n",
    "    # Use cv2.copyMakeBorder to add padding\n",
    "    padded_img = cv2.copyMakeBorder(img, top_pad, bottom_pad, left_pad, right_pad, 0)\n",
    "\n",
    "    # Save the result\n",
    "    cv2.imwrite(output_path, padded_img)\n",
    "\n",
    "# Example usage\n",
    "input_image_path = \"/workspace/nemo/data/aadhar_information_fetch/190203220000035_aadhaar.jpg\"\n",
    "output_image_path = \"12345678_123_rot.jpg\"\n",
    "pad_to_square(input_image_path, output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9bf44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def pad_to_square(input_image_path,output_image_path):\n",
    "    # Step 1: Read the rectangle image\n",
    "    # Step 2: Determine the size of the square image\n",
    "    rectangle_image = cv2.imread(image_path)\n",
    "    max_dim = max(rectangle_image.shape[0], rectangle_image.shape[1])\n",
    "    square_size = (max_dim, max_dim)\n",
    "\n",
    "    # Step 3: Create a new square image with a white background\n",
    "    square_image = np.ones((square_size[0], square_size[1], 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # Step 4: Place the rectangle image in the center of the square image\n",
    "    x_offset = (square_size[1] - rectangle_image.shape[1]) // 2\n",
    "    y_offset = (square_size[0] - rectangle_image.shape[0]) // 2\n",
    "    square_image[y_offset:y_offset+rectangle_image.shape[0], x_offset:x_offset+rectangle_image.shape[1]] = rectangle_image\n",
    "\n",
    "    # Step 5: Save or display the resulting square image\n",
    "    cv2.imwrite(output_image_path, square_image)\n",
    "\n",
    "\n",
    "# Replace 'input_image.jpg' with the path to your rectangle image\n",
    "# Replace 'output_image.jpg' with the desired path for the resulting square image\n",
    "input_image_path = \"/workspace/nemo/data/aadhar_information_fetch/190203220000034_aadhaar.jpg\"\n",
    "output_image_path = \"12345678___.jpg\"\n",
    "pad_to_square(input_image_path, output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e600940a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# find landmarks with retinaface ()\u001b[39;00m\n\u001b[1;32m      7\u001b[0m result \u001b[38;5;241m=\u001b[39m RetinaFace\u001b[38;5;241m.\u001b[39mdetect_faces(img__)\n\u001b[0;32m----> 8\u001b[0m landmarks \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mface_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlandmarks\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m left_eye \u001b[38;5;241m=\u001b[39m landmarks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_eye\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m right_eye \u001b[38;5;241m=\u001b[39m landmarks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright_eye\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from retinaface.commons import postprocess\n",
    "img_path='/workspac/enemo/data/aadhar_information_fetch/190203220000011_aadhaar.jpg'\n",
    "img_=cv2.imread(img_path)\n",
    "img__=pad_to_square(img_)\n",
    "\n",
    "# find landmarks with retinaface ()\n",
    "result = RetinaFace.detect_faces(img_path)\n",
    "landmarks = result[\"face_1\"][\"landmarks\"]\n",
    "left_eye = landmarks[\"left_eye\"]\n",
    "right_eye = landmarks[\"right_eye\"]\n",
    "nose = landmarks[\"nose\"]\n",
    "\n",
    "# align the original image with respect to the eye coordinates\n",
    "img = cv2.imread(img_path)\n",
    "img_aligned = postprocess.alignment_procedure(img, right_eye, left_eye, nose)\n",
    "cv2.imwrite('2323232.jpg',img_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "176013f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face_1': {'score': 0.9964152574539185,\n",
       "  'facial_area': [138, 210, 190, 253],\n",
       "  'landmarks': {'right_eye': [167.21619, 222.9769],\n",
       "   'left_eye': [168.49963, 236.93822],\n",
       "   'nose': [159.34995, 226.3375],\n",
       "   'mouth_right': [151.11731, 224.89655],\n",
       "   'mouth_left': [151.9283, 235.1583]}}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path=\"/workspace/nemo/data/aadhar_information_fetch/190203220000034_aadhaar.jpg\"\n",
    "result = RetinaFace.detect_faces(img_path)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93fc7bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('2323232__.jpg',img__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "474f51a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.BORDER_CONSTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e459b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def pad_to_square(img):\n",
    "    # Read the input image\n",
    "    #img = cv2.imread(image_path)\n",
    "\n",
    "    # Get the dimensions of the input image\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    # Determine the size of the target square image (use the maximum dimension)\n",
    "    target_size = max(height, width)\n",
    "\n",
    "    # Calculate the padding needed on each side\n",
    "    top_pad = (target_size - height) // 2\n",
    "    bottom_pad = target_size - height - top_pad\n",
    "    left_pad = (target_size - width) // 2\n",
    "    right_pad = target_size - width - left_pad\n",
    "\n",
    "    # Use cv2.copyMakeBorder to add padding\n",
    "    padded_img = cv2.copyMakeBorder(img, top_pad, bottom_pad, left_pad, right_pad, 0)\n",
    "\n",
    "    # Save the result\n",
    "    #cv2.imwrite(output_path, padded_img)\n",
    "    return padded_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a237cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_image_path = \"12345678_123.jpg\"\n",
    "pad_to_square(input_image_path, output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "301a4f10",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# find landmarks with retinaface ()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m result \u001b[38;5;241m=\u001b[39m RetinaFace\u001b[38;5;241m.\u001b[39mdetect_faces(img__)\n\u001b[0;32m----> 7\u001b[0m landmarks \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mface_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlandmarks\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m left_eye \u001b[38;5;241m=\u001b[39m landmarks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_eye\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m right_eye \u001b[38;5;241m=\u001b[39m landmarks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright_eye\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "input_image_path = \"/workspace/nemo/data/aadhar_information_fetch/190203220000011_aadhaar.jpg\"\n",
    "img_=cv2.imread(input_image_path)\n",
    "img__=pad_to_square(img_)\n",
    "\n",
    "# find landmarks with retinaface ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d8b3412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], shape=(0, 5), dtype=float64),\n",
       " array([], shape=(0, 5, 2), dtype=float64))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ae0cfd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m RetinaFace\u001b[38;5;241m.\u001b[39mdetect_faces(input_image_path)\n\u001b[0;32m----> 2\u001b[0m landmarks \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mface_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlandmarks\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m left_eye \u001b[38;5;241m=\u001b[39m landmarks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_eye\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m right_eye \u001b[38;5;241m=\u001b[39m landmarks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright_eye\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "result = RetinaFace.detect_faces(input_image_path)\n",
    "landmarks = result[\"face_1\"][\"landmarks\"]\n",
    "left_eye = landmarks[\"left_eye\"]\n",
    "right_eye = landmarks[\"right_eye\"]\n",
    "nose = landmarks[\"nose\"]\n",
    "\n",
    "# align the original image with respect to the eye coordinates\n",
    "img = cv2.imread(img_path)\n",
    "img_aligned = postprocess.alignment_procedure(img, right_eye, left_eye, nose)\n",
    "cv2.imwrite('2323232__.jpg',img_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9abd72a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/01/19 09:47:16] ppocr DEBUG: Namespace(alpha=1.0, alphacolor=(255, 255, 255), benchmark=False, beta=1.0, binarize=False, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_box_type='quad', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, fourier_degree=5, gpu_id=0, gpu_mem=500, help='==SUPPRESS==', image_dir=None, image_orientation=False, invert=False, ir_optim=True, kie_algorithm='LayoutXLM', label_list=['0', '180'], lang='en', layout=True, layout_dict_path=None, layout_model_dir=None, layout_nms_threshold=0.5, layout_score_threshold=0.5, max_batch_size=10, max_text_length=25, merge_no_span_structure=True, min_subgraph_size=15, mode='structure', ocr=True, ocr_order_method=None, ocr_version='PP-OCRv4', output='./output', page_num=0, precision='fp32', process_id=0, re_model_dir=None, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='/root/anaconda3/envs/id_detection/lib/python3.8/site-packages/paddleocr/ppocr/utils/en_dict.txt', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', recovery=False, save_crop_res=False, save_log_path='./log_output/', scales=[8, 16, 32], ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ser_model_dir=None, show_log=True, sr_batch_num=1, sr_image_shape='3, 32, 128', sr_model_dir=None, structure_version='PP-StructureV2', table=True, table_algorithm='TableAttn', table_char_dict_path=None, table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=True, use_dilation=False, use_gpu=False, use_mp=False, use_npu=False, use_onnx=False, use_pdf2docx_api=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_visual_backbone=True, use_xpu=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n",
      "[2024/01/19 09:47:17] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.24978280067443848\n",
      "[2024/01/19 09:47:17] ppocr DEBUG: cls num  : 3, elapsed : 0.02109217643737793\n",
      "[2024/01/19 09:47:17] ppocr DEBUG: rec_res num  : 3, elapsed : 0.12797284126281738\n",
      "[[[[[7.0, 58.0], [310.0, 32.0], [314.0, 73.0], [11.0, 100.0]], ('Snenendu Majhi', 0.8344805836677551)], [[[13.0, 119.0], [232.0, 100.0], [234.0, 131.0], [16.0, 150.0]], ('DO:20/01/1999', 0.9327830076217651)], [[[12.0, 174.0], [86.0, 170.0], [88.0, 208.0], [14.0, 212.0]], ('Male', 0.929710865020752)]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "input_image_path = \"/workspace/nemo/data/aadhar_information_fetch/adhar_body_test.jpg\"\n",
    "img=cv2.imread(input_image_path)\n",
    "img = cv2.resize(img, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
    "#convert the image to gray\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "OCR = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=True)\n",
    "text = OCR.ocr(img, cls=True)\n",
    "print(text)\n",
    "ocr_output = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86b72814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Snenendu Majhi\n",
      "Coordinates: [[7.0, 58.0], [310.0, 32.0], [314.0, 73.0], [11.0, 100.0]]\n",
      "Confidence: 0.8344805836677551\n",
      "\n",
      "Text: DO:20/01/1999\n",
      "Coordinates: [[13.0, 119.0], [232.0, 100.0], [234.0, 131.0], [16.0, 150.0]]\n",
      "Confidence: 0.9327830076217651\n",
      "\n",
      "Text: Male\n",
      "Coordinates: [[12.0, 174.0], [86.0, 170.0], [88.0, 208.0], [14.0, 212.0]]\n",
      "Confidence: 0.929710865020752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_details_with_confidence(data):\n",
    "    for entry in data:\n",
    "        for element in entry:\n",
    "            coordinates = element[0]\n",
    "            text = element[1][0]\n",
    "            confidence = element[1][1]\n",
    "\n",
    "            print(f\"Text: {text}\")\n",
    "            print(f\"Coordinates: {coordinates}\")\n",
    "            print(f\"Confidence: {confidence}\")\n",
    "            print()\n",
    "\n",
    "# Print details with confidence scores\n",
    "print_details_with_confidence(ocr_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b890f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_output = text\n",
    "test_list = list()\n",
    "len(ocr_output[0])\n",
    "for i in range(len(ocr_output[0])):\n",
    "    test_list.append(ocr_output[0][i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf679484",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m [(text, confidence) \u001b[38;5;28;01mfor\u001b[39;00m text, confidence \u001b[38;5;129;01min\u001b[39;00m test_list \u001b[38;5;28;01mif\u001b[39;00m confidence \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold]\n\u001b[1;32m      4\u001b[0m res \u001b[38;5;241m=\u001b[39m [lis[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m lis \u001b[38;5;129;01min\u001b[39;00m filtered_data]\n",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m [(text, confidence) \u001b[38;5;28;01mfor\u001b[39;00m text, confidence \u001b[38;5;129;01min\u001b[39;00m test_list \u001b[38;5;28;01mif\u001b[39;00m confidence \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mthreshold\u001b[49m]\n\u001b[1;32m      4\u001b[0m res \u001b[38;5;241m=\u001b[39m [lis[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m lis \u001b[38;5;129;01min\u001b[39;00m filtered_data]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'threshold' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "filtered_data = [(text, confidence) for text, confidence in test_list if confidence >= threshold]\n",
    "\n",
    "\n",
    "res = [lis[0] for lis in filtered_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a645892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Female',\n",
       " 'DB1109/1996',\n",
       " 'Renuka Lakra Oraon',\n",
       " 'Government of India',\n",
       " '76672483 6520',\n",
       " 'Line Haldiban Tea Garden DJapaigun',\n",
       " 'Addrass D/O Kastoo Lakra Oraon.manipur',\n",
       " '735203',\n",
       " 'Unique IdentificationAut',\n",
       " '7667 2483652']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "406f22e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: /Female, Confidence: 0.9101754426956177\n",
      "Text: DB1109/1996, Confidence: 0.8333147168159485\n",
      "Text: Renuka Lakra Oraon, Confidence: 0.9322106838226318\n",
      "Text: Government of India, Confidence: 0.9325658679008484\n",
      "Text: 76672483 6520, Confidence: 0.9600436091423035\n",
      "Text: Line Haldiban Tea Garden DJapaigun, Confidence: 0.8690483570098877\n",
      "Text: Addrass D/O Kastoo Lakra Oraon.manipur, Confidence: 0.8623363375663757\n",
      "Text: 735203, Confidence: 0.9958108067512512\n",
      "Text: Unique IdentificationAut, Confidence: 0.8462047576904297\n",
      "Text: 7667 2483652, Confidence: 0.9601871371269226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the threshold\n",
    "threshold = 0.8\n",
    "\n",
    "# Filter tuples with confidence above the threshold\n",
    "filtered_data = [(text, confidence) for text, confidence in data if confidence >= threshold]\n",
    "\n",
    "# Display the filtered information\n",
    "for item in filtered_data:\n",
    "    print(f\"Text: {item[0]}, Confidence: {item[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a61cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[347.0, 185.0], [369.0, 185.0], [365.0, 315.0], [343.0, 315.0]],\n",
       "  ('/Female', 0.9101754426956177)],\n",
       " [[[373.0, 184.0], [397.0, 184.0], [393.0, 429.0], [369.0, 429.0]],\n",
       "  ('DB1109/1996', 0.8333147168159485)],\n",
       " [[[398.0, 185.0], [419.0, 185.0], [419.0, 366.0], [398.0, 366.0]],\n",
       "  ('Renuka Lakra Oraon', 0.9322106838226318)],\n",
       " [[[456.0, 180.0], [486.0, 181.0], [477.0, 442.0], [447.0, 441.0]],\n",
       "  ('Government of India', 0.9325658679008484)],\n",
       " [[[181.0, 196.0], [214.0, 196.0], [214.0, 452.0], [181.0, 452.0]],\n",
       "  ('76672483 6520', 0.9600436091423035)],\n",
       " [[[134.0, 307.0], [172.0, 306.0], [176.0, 550.0], [138.0, 550.0]],\n",
       "  ('4', 0.6566982269287109)],\n",
       " [[[246.0, 831.0], [272.0, 829.0], [290.0, 1089.0], [264.0, 1091.0]],\n",
       "  ('Sinneg.West Benga735203', 0.7883525490760803)],\n",
       " [[[270.0, 832.0], [296.0, 831.0], [316.0, 1154.0], [290.0, 1156.0]],\n",
       "  ('Line Haldiban Tea Garden DJapaigun', 0.8690483570098877)],\n",
       " [[[294.0, 832.0], [319.0, 831.0], [339.0, 1163.0], [314.0, 1164.0]],\n",
       "  ('Addrass D/O Kastoo Lakra Oraon.manipur', 0.8623363375663757)],\n",
       " [[[348.0, 828.0], [370.0, 827.0], [375.0, 904.0], [352.0, 905.0]],\n",
       "  ('735203', 0.9958108067512512)],\n",
       " [[[371.0, 826.0], [396.0, 825.0], [411.0, 1100.0], [386.0, 1102.0]],\n",
       "  ('..', 0.6898112297058105)],\n",
       " [[[396.0, 825.0], [417.0, 823.0], [427.0, 989.0], [405.0, 990.0]],\n",
       "  ('R.', 0.5574471354484558)],\n",
       " [[[457.0, 957.0], [487.0, 956.0], [496.0, 1198.0], [466.0, 1199.0]],\n",
       "  ('Unique IdentificationAut', 0.8462047576904297)],\n",
       " [[[192.0, 991.0], [227.0, 988.0], [244.0, 1194.0], [209.0, 1197.0]],\n",
       "  ('7667 2483652', 0.9601871371269226)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a0e167c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aadhaar_prediction\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'predict'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82939b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "103a4e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from retinaface.commons import postprocess\n",
    "from retinaface import RetinaFace\n",
    "import matplotlib as plt\n",
    "import cv2\n",
    "\n",
    "img_path = \"12345678___.jpg\"\n",
    "\n",
    "# find landmarks with retinaface ()\n",
    "result = RetinaFace.detect_faces(img_path)\n",
    "landmarks = result[\"face_1\"][\"landmarks\"]\n",
    "left_eye = landmarks[\"left_eye\"]\n",
    "right_eye = landmarks[\"right_eye\"]\n",
    "nose = landmarks[\"nose\"]\n",
    "\n",
    "# align the original image with respect to the eye coordinates\n",
    "img = cv2.imread(img_path)\n",
    "img_aligned = postprocess.alignment_procedure(img, right_eye, left_eye, nose)\n",
    "img_aligned = img_aligned[:,:,::-1]\n",
    "image_ = cv2.cvtColor(img_aligned, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cv2.imwrite('123.jpg',image_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a840d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def pad_to_square(input_image_path,output_image_path):\n",
    "    # Step 1: Read the rectangle image\n",
    "    # Step 2: Determine the size of the square image\n",
    "    rectangle_image = cv2.imread(input_image_path)\n",
    "    max_dim = max(rectangle_image.shape[0], rectangle_image.shape[1])\n",
    "    square_size = (max_dim, max_dim)\n",
    "\n",
    "    # Step 3: Create a new square image with a white background\n",
    "    square_image = np.ones((square_size[0], square_size[1], 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # Step 4: Place the rectangle image in the center of the square image\n",
    "    x_offset = (square_size[1] - rectangle_image.shape[1]) // 2\n",
    "    y_offset = (square_size[0] - rectangle_image.shape[0]) // 2\n",
    "    square_image[y_offset:y_offset+rectangle_image.shape[0], x_offset:x_offset+rectangle_image.shape[1]] = rectangle_image\n",
    "\n",
    "    # Step 5: Save or display the resulting square image\n",
    "    cv2.imwrite(output_image_path, square_image)\n",
    "\n",
    "\n",
    "# Replace 'input_image.jpg' with the path to your rectangle image\n",
    "# Replace 'output_image.jpg' with the desired path for the resulting square image\n",
    "input_image_path = \"/workspace/nemo/data/aadhar_information_fetch/aadhaar_nic/Amalesh.jpeg\"\n",
    "output_image_path = \"12345678___.jpg\"\n",
    "pad_to_square(input_image_path, output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6fb65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('123.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26256606",
   "metadata": {},
   "outputs": [],
   "source": [
    "191803220000106_aadhaar.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6fd4ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 infos, 5.8ms\n",
      "Speed: 1.8ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#body predict code \n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "img=cv2.imread('/workspace/nemo/data/aadhar_information_fetch/aadhaar_nic/Arnab.jpeg')\n",
    "labels = {\n",
    "    'aadhaar_body': 0.0\n",
    "}\n",
    "result = ''\n",
    "file_path0 = os.path.abspath(os.path.join(os.path.dirname('__file__'), \"..\"))\n",
    "model_path ='/workspace/nemo/data/aadhar_information_fetch/model_weight/aadhar_body.pt'#os.path.join(file_path0, 'aadhar_information_fetch','model_weight','aadhar_body.pt')\n",
    "model = YOLO(model_path)\n",
    "#     try:\n",
    "results = model(source=img ,save=True)[0]  # results list\n",
    "#         img = cv2.imread(image_path)\n",
    "for r in results.boxes.data.tolist():\n",
    "    x1, y1, x2, y2, score, class_id = r\n",
    "    if class_id == 0.0:   \n",
    "        image_crop = img[int(y1):int(y2), int(x1):int(x2), :]\n",
    "        cv2.imwrite('adhar_body_test.jpg', image_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "931c3252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/01/18 09:58:44] ppocr DEBUG: Namespace(alpha=1.0, alphacolor=(255, 255, 255), benchmark=False, beta=1.0, binarize=False, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_box_type='quad', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, fourier_degree=5, gpu_id=0, gpu_mem=500, help='==SUPPRESS==', image_dir=None, image_orientation=False, invert=False, ir_optim=True, kie_algorithm='LayoutXLM', label_list=['0', '180'], lang='en', layout=True, layout_dict_path=None, layout_model_dir=None, layout_nms_threshold=0.5, layout_score_threshold=0.5, max_batch_size=10, max_text_length=25, merge_no_span_structure=True, min_subgraph_size=15, mode='structure', ocr=True, ocr_order_method=None, ocr_version='PP-OCRv4', output='./output', page_num=0, precision='fp32', process_id=0, re_model_dir=None, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='/root/anaconda3/envs/id_detection/lib/python3.8/site-packages/paddleocr/ppocr/utils/en_dict.txt', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', recovery=False, save_crop_res=False, save_log_path='./log_output/', scales=[8, 16, 32], ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ser_model_dir=None, show_log=True, sr_batch_num=1, sr_image_shape='3, 32, 128', sr_model_dir=None, structure_version='PP-StructureV2', table=True, table_algorithm='TableAttn', table_char_dict_path=None, table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=True, use_dilation=False, use_gpu=False, use_mp=False, use_npu=False, use_onnx=False, use_pdf2docx_api=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_visual_backbone=True, use_xpu=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n",
      "[2024/01/18 09:58:46] ppocr DEBUG: dt_boxes num : 27, elapsed : 0.18624472618103027\n",
      "[2024/01/18 09:58:46] ppocr DEBUG: cls num  : 27, elapsed : 0.10323309898376465\n",
      "[2024/01/18 09:58:46] ppocr DEBUG: rec_res num  : 27, elapsed : 0.42127203941345215\n",
      "Text: Government of India\n",
      "Coordinates: [[88.0, 24.0], [193.0, 24.0], [193.0, 37.0], [88.0, 37.0]]\n",
      "Confidence: 0.9400029182434082\n",
      "\n",
      "Text: Unique Identification Authority ofIndia\n",
      "Coordinates: [[435.0, 22.0], [639.0, 22.0], [639.0, 35.0], [435.0, 35.0]]\n",
      "Confidence: 0.9456087946891785\n",
      "\n",
      "Text: 108\n",
      "Coordinates: [[371.0, 48.0], [562.0, 48.0], [562.0, 61.0], [371.0, 61.0]]\n",
      "Confidence: 0.8314763903617859\n",
      "\n",
      "Text: Issue Date : 08/04/2014\n",
      "Coordinates: [[5.0, 57.0], [18.0, 57.0], [18.0, 141.0], [5.0, 141.0]]\n",
      "Confidence: 0.9765461683273315\n",
      "\n",
      "Text: Chitradip Sarkar\n",
      "Coordinates: [[116.0, 62.0], [185.0, 62.0], [185.0, 73.0], [116.0, 73.0]]\n",
      "Confidence: 0.9824706315994263\n",
      "\n",
      "Text: -733103\n",
      "Coordinates: [[370.0, 59.0], [450.0, 59.0], [450.0, 69.0], [370.0, 69.0]]\n",
      "Confidence: 0.9489570260047913\n",
      "\n",
      "Text: DOB:13/08/1997\n",
      "Coordinates: [[115.0, 72.0], [230.0, 72.0], [230.0, 85.0], [115.0, 85.0]]\n",
      "Confidence: 0.932155191898346\n",
      "\n",
      "Text: Address:\n",
      "Coordinates: [[365.0, 75.0], [416.0, 76.0], [416.0, 87.0], [364.0, 86.0]]\n",
      "Confidence: 0.9845204949378967\n",
      "\n",
      "Text: /MALE\n",
      "Coordinates: [[117.0, 85.0], [166.0, 85.0], [166.0, 96.0], [117.0, 96.0]]\n",
      "Confidence: 0.9110827445983887\n",
      "\n",
      "Text: 108-AMRITA KHANDA,malancha\n",
      "Coordinates: [[369.0, 85.0], [523.0, 85.0], [523.0, 98.0], [369.0, 98.0]]\n",
      "Confidence: 0.9311679601669312\n",
      "\n",
      "Text: Malancha,Dakshin Dinajpur,\n",
      "Coordinates: [[369.0, 93.0], [491.0, 95.0], [491.0, 108.0], [369.0, 106.0]]\n",
      "Confidence: 0.9220601320266724\n",
      "\n",
      "Text: West Bengal-733103\n",
      "Coordinates: [[365.0, 105.0], [466.0, 104.0], [466.0, 114.0], [365.0, 115.0]]\n",
      "Confidence: 0.964435875415802\n",
      "\n",
      "Text: XXXXXXXX1162\n",
      "Coordinates: [[111.0, 177.0], [232.0, 175.0], [232.0, 189.0], [112.0, 191.0]]\n",
      "Confidence: 0.7176513075828552\n",
      "\n",
      "Text: XXXXXXXX1162\n",
      "Coordinates: [[475.0, 177.0], [595.0, 177.0], [595.0, 190.0], [475.0, 190.0]]\n",
      "Confidence: 0.7646691203117371\n",
      "\n",
      "Text: VID:9107 422116569939\n",
      "Coordinates: [[101.0, 192.0], [248.0, 192.0], [248.0, 205.0], [101.0, 205.0]]\n",
      "Confidence: 0.9485440850257874\n",
      "\n",
      "Text: VID:91074221 1656 9939\n",
      "Coordinates: [[466.0, 192.0], [611.0, 192.0], [611.0, 205.0], [466.0, 205.0]]\n",
      "Confidence: 0.9334526658058167\n",
      "\n",
      "Text: 1947\n",
      "Coordinates: [[383.0, 206.0], [433.0, 204.0], [434.0, 218.0], [383.0, 220.0]]\n",
      "Confidence: 0.9550576210021973\n",
      "\n",
      "Text:  help@uidai.gov.in| www.uidai.gov.in\n",
      "Coordinates: [[462.0, 206.0], [698.0, 206.0], [698.0, 219.0], [462.0, 219.0]]\n",
      "Confidence: 0.9089299440383911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# body paddle ocr read code \n",
    "import cv2\n",
    "from paddleocr import PaddleOCR\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "input_image_path = \"/workspace/nemo/data/aadhar_information_fetch/aadhaar_nic/Chitradip.jpeg\"\n",
    "img=cv2.imread(input_image_path)\n",
    "#img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "#convert the image to gray\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "OCR = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=True)\n",
    "text = OCR.ocr(img, cls=True)\n",
    "#print(text[0])\n",
    "def print_details_with_confidence(data):\n",
    "    for entry in data:\n",
    "        for element in entry:\n",
    "            coordinates = element[0]\n",
    "            text = element[1][0]\n",
    "            confidence = element[1][1]\n",
    "\n",
    "            print(f\"Text: {text}\")\n",
    "            print(f\"Coordinates: {coordinates}\")\n",
    "            print(f\"Confidence: {confidence}\")\n",
    "            print()\n",
    "\n",
    "# Print details with confidence scores\n",
    "print_details_with_confidence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93765f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=['Government of ndia', '/2014' ,'Chitradip Sarkar', 'D013/08/1997', 'MALE', 'VJD9107 4221 1656 9939']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a929bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Government of ndia None 1\n",
      "None ---------------2\n",
      "/2014 None 1\n",
      "None ---------------2\n",
      "Chitradip Sarkar None 1\n",
      "None ---------------2\n",
      "D013/08/1997 None 1\n",
      "None ---------------2\n",
      "MALE None 1\n",
      "None ---------------2\n",
      "VJD9107 4221 1656 9939 <re.Match object; span=(0, 3), match='vjd'> 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "aadhar_number=\" \"\n",
    "for b in a :\n",
    "    #print(b)\n",
    "    pattern = re.compile(r'vid|vd |vi|vjd')\n",
    "    match = re.search(pattern, b.lower())\n",
    "    print(b,match,'1')\n",
    "    aadhar_pattern =re.compile(r'\\b\\d(?:\\s?\\d){11}\\b')# re.compile(r'\\b(?:\\d[ -]*){12}\\b')\n",
    "    if not (match):\n",
    "        aadhar_match = re.search(aadhar_pattern, b.lower())\n",
    "        print(aadhar_match,'---------------2')\n",
    "        if (aadhar_match):\n",
    "            aadhar_number=aadhar_match.group()\n",
    "            print(aadhar_number)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6ffa41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/01/1999\n"
     ]
    }
   ],
   "source": [
    "date_list = ['20', '1', '1999']\n",
    "\n",
    "# Ensure day and month have leading zeros\n",
    "day = date_list[0].zfill(2)\n",
    "month = date_list[1].zfill(2)\n",
    "year = date_list[2]\n",
    "\n",
    "# Format the date as dd/mm/yyyy\n",
    "formatted_date = f'{day}/{month}/{year}'\n",
    "\n",
    "print(formatted_date)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e8659be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1999'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "date_list = ['1999']\n",
    "if len(date_list) == 1:\n",
    "    formatted_date = datetime.strptime(date_list[0], '%Y').strftime('%Y')\n",
    "formatted_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9379cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52245e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "id_detection",
   "language": "python",
   "name": "id_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
